{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore stock market dataset from Yahoo Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load broad market indicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "broad_market_indicies = '^SPX ^NDX ^VIX ^RUT DX-Y.NYB ^TNX'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "broad_market = yf.download(broad_market_indicies, period='max') \n",
    "broad_market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "broad_market.to_csv('data/broad_market.csv.bz2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Sector Indicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sector_indicies = 'XLE ^SP500-15 ^SP500-20 ^SP500-25 ^SP500-30 ^SP500-35 ^SP500-40 ^SP500-45 ^SP500-50 ^SP500-55 ^SP500-60'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sectors = yf.download(sector_indicies, period='max') \n",
    "sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sectors.to_csv('data/sectors.csv.bz2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Growth Stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ibd50 = pd.read_csv('data/IBD50.csv')\n",
    "ibd50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibd250 = pd.read_csv('data/IBD250.csv')\n",
    "ibd250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge IBD 50 and 250 symbol sets\n",
    "ibd50_set = set(ibd50['Symbol'])\n",
    "ibd250_set = set(ibd250['Symbol'])\n",
    "ibd_growth_set = ibd50_set.union(ibd250_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ibd_growth_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibdgrowth_str = ' '.join(ibd_growth_set)\n",
    "ibdgrowth_str\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibdgrowth_data = yf.download(ibdgrowth_str, period='max', group_by='tickers') \n",
    "ibdgrowth_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibdgrowth_data.columns.levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ticker in ibd50_data.columns.levels[0]:\n",
    "#    print(f'ticker: {ticker}')\n",
    "#    ticker_data = ibd50_data[ticker]\n",
    "#    print(f'ticker historic data: {ticker_data}')\n",
    "#    # remove missing values\n",
    "#    ticker_data = ticker_data.dropna()\n",
    "#    print(f'ticker historic data: {ticker_data}')\n",
    "#    # save ticker data\n",
    "#    ticker_data.to_csv(f'data/{ticker}.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibdgrowth_data.to_csv('data/ibdgrowth_hist.csv.bz2', index='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibdgrowth_loaded = pd.read_csv('data/ibdgrowth_hist.csv.bz2', header=[0, 1], index_col=0)\n",
    "ibdgrowth_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = ibdgrowth_loaded.columns.levels[0][0]\n",
    "print(f'ticker: {ticker}')\n",
    "ticker_data = ibdgrowth_loaded[ticker]\n",
    "print(f'ticker historic data: {ticker_data}')\n",
    "# remove missing values\n",
    "ticker_data = ticker_data.dropna()\n",
    "print(f'ticker historic data without missing data: {ticker_data}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv('data/ibd50_hist.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "msft = yf.Ticker(\"MSFT\")\n",
    "print(msft)\n",
    "\"\"\"\n",
    "returns\n",
    "<yfinance.Ticker object at 0x1a1715e898>\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# get stock info\n",
    "print(json.dumps(msft.info, indent=2))\n",
    "\n",
    "\"\"\"\n",
    "returns:\n",
    "{\n",
    " 'quoteType': 'EQUITY',\n",
    " 'quoteSourceName': 'Nasdaq Real Time Price',\n",
    " 'currency': 'USD',\n",
    " 'shortName': 'Microsoft Corporation',\n",
    " 'exchangeTimezoneName': 'America/New_York',\n",
    "  ...\n",
    " 'symbol': 'MSFT'\n",
    "}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get historical market data\n",
    "msft_hist = msft.history(period=\"max\")\n",
    "print(msft_hist)\n",
    "\"\"\"\n",
    "returns:\n",
    "              Open    High    Low    Close      Volume  Dividends  Splits\n",
    "Date\n",
    "1986-03-13    0.06    0.07    0.06    0.07  1031788800        0.0     0.0\n",
    "1986-03-14    0.07    0.07    0.07    0.07   308160000        0.0     0.0\n",
    "...\n",
    "2019-04-15  120.94  121.58  120.57  121.05    15792600        0.0     0.0\n",
    "2019-04-16  121.64  121.65  120.10  120.77    14059700        0.0     0.0\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show actions (dividends, splits)\n",
    "print(msft.actions)\n",
    "\"\"\"\n",
    "returns:\n",
    "            Dividends  Splits\n",
    "Date\n",
    "1987-09-21       0.00     2.0\n",
    "1990-04-16       0.00     2.0\n",
    "...\n",
    "2018-11-14       0.46     0.0\n",
    "2019-02-20       0.46     0.0\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# show dividends\n",
    "print(msft.dividends)\n",
    "\"\"\"\n",
    "returns:\n",
    "Date\n",
    "2003-02-19    0.08\n",
    "2003-10-15    0.16\n",
    "...\n",
    "2018-11-14    0.46\n",
    "2019-02-20    0.46\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show splits\n",
    "print(msft.splits)\n",
    "\"\"\"\n",
    "returns:\n",
    "Date\n",
    "1987-09-21    2.0\n",
    "1990-04-16    2.0\n",
    "...\n",
    "1999-03-29    2.0\n",
    "2003-02-18    2.0\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msft_hist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msft_hist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a deep copy so we can experiment with data without triggering unnecessary downloads \n",
    "df=msft_hist.copy(deep=True)\n",
    "\n",
    "# df=msft_hist.reset_index(drop=True)\n",
    "# data['Date']=pd.to_datetime(data['Date'])\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ingest data into darts timeseries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count rows without values\n",
    "# https://stackoverflow.com/questions/28199524/best-way-to-count-the-number-of-rows-with-missing-values-in-a-pandas-dataframe\n",
    "df.shape[0] - df.dropna().shape[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count any cells without values\n",
    "df.isnull().values.ravel().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert data to timeseries format that models can work with\n",
    "\n",
    "Regular time intervals between data points and no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Clean up date index. Remove time zone.\n",
    "df.index = pd.to_datetime(df.index, utc=True).date\n",
    "df.index = pd.to_datetime(df.index, utc=True)\n",
    "df.index.name = 'Date'\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts import TimeSeries\n",
    "\n",
    "series = TimeSeries.from_dataframe(df, fill_missing_dates=True, freq='B') # value_cols=[\"Close\"],  \"Open\", \"High\", \"Low\", \"Close\", \"Volume\", \"Dividends\", \"Stock Splits\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get regularized time series with NaN fill-ins\n",
    "reg_df = series.pd_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of rows without values\n",
    "reg_df.shape[0] - reg_df.dropna().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in missing values\n",
    "reg_df = reg_df.interpolate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check again number of rows without values. Should be 0.\n",
    "reg_df.shape[0] - reg_df.dropna().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update series with new regularized dates and values\n",
    "series = TimeSeries.from_dataframe(reg_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save prepared timeseries data to local csv for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_name = 'data/market_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# series.to_csv(data_file_name)\n",
    "series.to_csv(data_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure data can load back into timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = TimeSeries.from_csv(data_file_name, time_col='Date') #, freq='B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get regularized time series with NaN fill-ins\n",
    "loaded_df = series.pd_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of rows without values\n",
    "loaded_df.shape[0] - loaded_df.dropna().shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
