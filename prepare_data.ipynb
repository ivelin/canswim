{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore stock market dataset from Yahoo Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load broad market indicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture S&P500, NASDAQ100 and Russell 200 indecies and their equal weighted counter parts\n",
    "# As well as VIX volatility index, DYX US Dollar index and TNX US 10 Year Treasuries Rate Index\n",
    "broad_market_indicies = '^SPX ^SPXEW ^NDX ^NDXE ^RUT ^R2ESC ^VIX DX-Y.NYB ^TNX'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "broad_market = yf.download(broad_market_indicies, period='max', group_by='tickers') \n",
    "broad_market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "broad_market.to_csv('data/broad_market.csv.bz2', index='Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Sector Indicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sector_indicies = 'XLE ^SP500-15 ^SP500-20 ^SP500-25 ^SP500-30 ^SP500-35 ^SP500-40 ^SP500-45 ^SP500-50 ^SP500-55 ^SP500-60'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sectors = yf.download(sector_indicies, period='max') \n",
    "sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sectors.to_csv('data/sectors.csv.bz2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Growth Stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ibd50 = pd.read_csv('data/IBD50.csv')\n",
    "ibd50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibd250 = pd.read_csv('data/IBD250.csv')\n",
    "ibd250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge IBD 50 and 250 symbol sets\n",
    "ibd50_set = set(ibd50['Symbol'])\n",
    "ibd250_set = set(ibd250['Symbol'])\n",
    "ibd_growth_set = ibd50_set.union(ibd250_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ibd_growth_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibdgrowth_str = ' '.join(ibd_growth_set)\n",
    "ibdgrowth_str\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibdgrowth_data = yf.download(ibdgrowth_str, period='max', group_by='tickers') \n",
    "ibdgrowth_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibdgrowth_data.columns.levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ticker in ibd50_data.columns.levels[0]:\n",
    "#    print(f'ticker: {ticker}')\n",
    "#    ticker_data = ibd50_data[ticker]\n",
    "#    print(f'ticker historic data: {ticker_data}')\n",
    "#    # remove missing values\n",
    "#    ticker_data = ticker_data.dropna()\n",
    "#    print(f'ticker historic data: {ticker_data}')\n",
    "#    # save ticker data\n",
    "#    ticker_data.to_csv(f'data/{ticker}.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibdgrowth_data.to_csv('data/ibdgrowth_hist.csv.bz2', index='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibdgrowth_loaded = pd.read_csv('data/ibdgrowth_hist.csv.bz2', header=[0, 1], index_col=0)\n",
    "ibdgrowth_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ticker in ibdgrowth_loaded.columns.levels[0][:2]:\n",
    "    print(f'ticker: {ticker}')\n",
    "    ticker_data = ibdgrowth_loaded[ticker]\n",
    "    print(f'ticker historic data: {ticker_data}')\n",
    "    # remove missing values\n",
    "    ticker_data = ticker_data.dropna()\n",
    "    print(f'ticker historic data without missing data: {ticker_data}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load historical stock sales and earnings data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "FMP_API_KEY=os.getenv(\"FMP_API_KEY\")\n",
    "\n",
    "print(f'FMP_API_KEY={FMP_API_KEY}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fmpsdk\n",
    "\n",
    "# Company Valuation Methods\n",
    "symbol: str = \"AAPL\"\n",
    "symbols: [\"AAPL\", \"CSCO\", \"QQQQ\"]\n",
    "exchange: str = \"NYSE\"\n",
    "exchanges: [\"NYSE\", \"NASDAQ\"]\n",
    "query: str = \"AA\"\n",
    "limit: int = 3\n",
    "period: str = \"quarter\"\n",
    "download: bool = True\n",
    "market_cap_more_than: int = 1000000000\n",
    "beta_more_than: int = 1\n",
    "volume_more_than: int = 10000\n",
    "sector: str = \"Technology\"\n",
    "dividend_more_than: int = 0\n",
    "industry: str = \"Software\"\n",
    "filing_type: str = \"10-K\"\n",
    "print(f\"Company Profile: {fmpsdk.company_profile(apikey=FMP_API_KEY, symbol=symbol)=}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there should be no duplicate symbols in this list\n",
    "assert not ibdgrowth_loaded.columns.levels[0].duplicated().any() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earnings_all_df = pd.DataFrame()\n",
    "for ticker in ibdgrowth_loaded.columns.levels[0]:\n",
    "    earnings = fmpsdk.historical_earning_calendar(apikey=FMP_API_KEY, symbol=ticker, limit=-1)\n",
    "    if earnings is not None and len(earnings) > 0:\n",
    "        edf = pd.DataFrame(earnings)\n",
    "        edf['date'] = pd.to_datetime(edf['date'])\n",
    "        edf = edf.set_index(['symbol', 'date'])\n",
    "        print(f\"Earnings calendar for {ticker}: \\n{edf}\")\n",
    "        # edf = edf.pivot(columns='symbol')\n",
    "        # edf.swaplevel(i=0,j=1, axis=0)\n",
    "        # edf.drop(columns=['symbol'])\n",
    "        earnings_all_df = pd.concat([earnings_all_df, edf])\n",
    "        print(f\"Earnings calendar after pivot for {ticker}: \\n{edf}\")\n",
    "        n_earnings = len(earnings)\n",
    "        print(f\"Total earnings reports for {ticker}: {n_earnings}\")\n",
    "#    earliest_earn = earnings[-1] if len(earnings > 0 else 'None')\n",
    "#    print(f\"Earliest earnings report for {ticker}: {earliest_earn}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaon = earnings_all_df.loc[['AAON']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(earnings_all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earnings_all_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure there are no duplicate entries with composite index (date, symbol)\n",
    "assert not earnings_all_df.index.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupes = earnings_all_df[earnings_all_df.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupes.to_csv('data/dupes_earnings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earnings_file = 'data/earnings_calendar.csv.bz2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earnings_all_df.to_csv(earnings_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read back data and verify it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "earnings_loaded_df = pd.read_csv('data/earnings_calendar.csv.bz2', index_col=['symbol', 'date'])\n",
    "print(earnings_loaded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not earnings_loaded_df.index.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupes = earnings_loaded_df.loc['AAON'].duplicated().any()\n",
    "#  and earnings_loaded_df.duplicated(keep=False)\n",
    "dupes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if data for a given symbol was saved and loaded as expected\n",
    "earnings_loaded_df.loc[['AAON']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert date strings to numerical representation\n",
    "ufd = pd.to_datetime(earnings_loaded_df['updatedFromDate'])\n",
    "ufd_year = ufd.dt.year\n",
    "ufd_month = ufd.dt.month\n",
    "ufd_day = ufd.dt.day\n",
    "\n",
    "earn_n_cols = len(earnings_loaded_df.columns)\n",
    "earnings_loaded_df.insert(loc=earn_n_cols, column='updatedFromDate_year', value=ufd_year)\n",
    "earnings_loaded_df.insert(loc=earn_n_cols, column='updatedFromDate_month', value=ufd_month)\n",
    "earnings_loaded_df.insert(loc=earn_n_cols, column='updatedFromDate_day', value=ufd_day)\n",
    "earnings_loaded_df.pop('updatedFromDate')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earnings_loaded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert date strings to numerical representation\n",
    "fde = pd.to_datetime(earnings_loaded_df['fiscalDateEnding'])\n",
    "fde_year = ufd.dt.year\n",
    "fde_month = ufd.dt.month\n",
    "fde_day = ufd.dt.day\n",
    "\n",
    "earn_n_cols = len(earnings_loaded_df.columns)\n",
    "earnings_loaded_df.insert(loc=earn_n_cols, column='fiscalDateEnding_year', value=fde_year)\n",
    "earnings_loaded_df.insert(loc=earn_n_cols, column='fiscalDateEnding_month', value=fde_month)\n",
    "earnings_loaded_df.insert(loc=earn_n_cols, column='fiscalDateEnding_day', value=fde_day)\n",
    "earnings_loaded_df.pop('fiscalDateEnding')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earnings_loaded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert earnings reporting time - Before Market Open / After Market Close - categories to numerical representation\n",
    "earnings_loaded_df['time'] = earnings_loaded_df['time'].replace(['bmo', 'amc', '--'],\n",
    "                        [0, 1, -1], inplace=False).astype('int32')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earnings_loaded_df.loc[earnings_loaded_df['time'] == '--']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earnings_loaded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts import TimeSeries\n",
    "\n",
    "type(earnings_loaded_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earnings_loaded_df.index.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earnings_loaded_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = earnings_loaded_df.index.get_level_values('symbol').unique()\n",
    "for t in tickers:\n",
    "    t_earn = earnings_loaded_df.loc[[t]]\n",
    "    t_earn = t_earn.droplevel('symbol')\n",
    "    t_earn.index = pd.to_datetime(t_earn.index)\n",
    "    print(f'index type for {t}: {type(t_earn.index)}')\n",
    "    assert not t_earn.index.duplicated().any()\n",
    "    print(f'{t} earnings: \\n{t_earn}')\n",
    "    t_earn_series = TimeSeries.from_dataframe(t_earn, fillna_value=-1, freq='D', fill_missing_dates=True)\n",
    "    assert len(t_earn_series.gaps()) == 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_earn.loc[t_earn.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with other stock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_earn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "msft = yf.Ticker(\"MSFT\")\n",
    "print(msft)\n",
    "\"\"\"\n",
    "returns\n",
    "<yfinance.Ticker object at 0x1a1715e898>\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# get stock info\n",
    "print(json.dumps(msft.info, indent=2))\n",
    "\n",
    "\"\"\"\n",
    "returns:\n",
    "{\n",
    " 'quoteType': 'EQUITY',\n",
    " 'quoteSourceName': 'Nasdaq Real Time Price',\n",
    " 'currency': 'USD',\n",
    " 'shortName': 'Microsoft Corporation',\n",
    " 'exchangeTimezoneName': 'America/New_York',\n",
    "  ...\n",
    " 'symbol': 'MSFT'\n",
    "}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get historical market data\n",
    "msft_hist = msft.history(period=\"max\")\n",
    "print(msft_hist)\n",
    "\"\"\"\n",
    "returns:\n",
    "              Open    High    Low    Close      Volume  Dividends  Splits\n",
    "Date\n",
    "1986-03-13    0.06    0.07    0.06    0.07  1031788800        0.0     0.0\n",
    "1986-03-14    0.07    0.07    0.07    0.07   308160000        0.0     0.0\n",
    "...\n",
    "2019-04-15  120.94  121.58  120.57  121.05    15792600        0.0     0.0\n",
    "2019-04-16  121.64  121.65  120.10  120.77    14059700        0.0     0.0\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show actions (dividends, splits)\n",
    "print(msft.actions)\n",
    "\"\"\"\n",
    "returns:\n",
    "            Dividends  Splits\n",
    "Date\n",
    "1987-09-21       0.00     2.0\n",
    "1990-04-16       0.00     2.0\n",
    "...\n",
    "2018-11-14       0.46     0.0\n",
    "2019-02-20       0.46     0.0\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# show dividends\n",
    "print(msft.dividends)\n",
    "\"\"\"\n",
    "returns:\n",
    "Date\n",
    "2003-02-19    0.08\n",
    "2003-10-15    0.16\n",
    "...\n",
    "2018-11-14    0.46\n",
    "2019-02-20    0.46\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show splits\n",
    "print(msft.splits)\n",
    "\"\"\"\n",
    "returns:\n",
    "Date\n",
    "1987-09-21    2.0\n",
    "1990-04-16    2.0\n",
    "...\n",
    "1999-03-29    2.0\n",
    "2003-02-18    2.0\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msft_hist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msft_hist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a deep copy so we can experiment with data without triggering unnecessary downloads \n",
    "df=msft_hist.copy(deep=True)\n",
    "\n",
    "# df=msft_hist.reset_index(drop=True)\n",
    "# data['Date']=pd.to_datetime(data['Date'])\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ingest data into darts timeseries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count rows without values\n",
    "# https://stackoverflow.com/questions/28199524/best-way-to-count-the-number-of-rows-with-missing-values-in-a-pandas-dataframe\n",
    "df.shape[0] - df.dropna().shape[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count any cells without values\n",
    "df.isnull().values.ravel().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert data to timeseries format that models can work with\n",
    "\n",
    "Regular time intervals between data points and no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Clean up date index. Remove time zone.\n",
    "df.index = pd.to_datetime(df.index, utc=True).date\n",
    "df.index = pd.to_datetime(df.index, utc=True)\n",
    "df.index.name = 'Date'\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts import TimeSeries\n",
    "\n",
    "series = TimeSeries.from_dataframe(df, fill_missing_dates=True, freq='B') # value_cols=[\"Close\"],  \"Open\", \"High\", \"Low\", \"Close\", \"Volume\", \"Dividends\", \"Stock Splits\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get regularized time series with NaN fill-ins\n",
    "reg_df = series.pd_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of rows without values\n",
    "reg_df.shape[0] - reg_df.dropna().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in missing values\n",
    "reg_df = reg_df.interpolate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check again number of rows without values. Should be 0.\n",
    "reg_df.shape[0] - reg_df.dropna().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update series with new regularized dates and values\n",
    "series = TimeSeries.from_dataframe(reg_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save prepared timeseries data to local csv for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_name = 'data/msft_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# series.to_csv(data_file_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure data can load back into timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# series = TimeSeries.from_csv(data_file_name, time_col='Date') #, freq='B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get regularized time series with NaN fill-ins\n",
    "loaded_df = series.pd_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of rows without values\n",
    "loaded_df.shape[0] - loaded_df.dropna().shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
